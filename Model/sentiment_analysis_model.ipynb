{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('imdb.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_Number</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2148</td>\n",
       "      <td>first think another Disney movie, might good, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23577</td>\n",
       "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1319</td>\n",
       "      <td>big fan Stephen King's work, film made even gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13358</td>\n",
       "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495</td>\n",
       "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2154</td>\n",
       "      <td>memory \"The Last Hunt\" stuck since saw 1956 13...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19880</td>\n",
       "      <td>Shakespeare fan, appreciate Ken Branagh done b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2073</td>\n",
       "      <td>privilege watching Scarface big screen beautif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12001</td>\n",
       "      <td>real classic. shipload sailors trying get town...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9373</td>\n",
       "      <td>Serials short subjects originally shown theate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19704</td>\n",
       "      <td>strange sex comedy there`s little comedy whole...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20033</td>\n",
       "      <td>many problems film, worst continuity; re-editi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21530</td>\n",
       "      <td>Rosie wasted lot TV time talking Tainos super ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6972</td>\n",
       "      <td>Man, people got chill. movie artistic genius. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5145</td>\n",
       "      <td>great movie could Soylent Green. scenes people...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2317</td>\n",
       "      <td>Wonderful family drama/comedy starring MacClai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6140</td>\n",
       "      <td>\"Ko tamo peva\" one best films ever saw. tragic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4585</td>\n",
       "      <td>quite long time life, either like film, liked ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1673</td>\n",
       "      <td>\"Kolchak\" TV series really didn't fit category...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3930</td>\n",
       "      <td>It's rare find literary work adequately transl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18860</td>\n",
       "      <td>awful, awful! old room mate used watch junk dr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3156</td>\n",
       "      <td>mom recently become addicted show, laughing bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8187</td>\n",
       "      <td>okay, plain dumb. bad horror/comedy film. read...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1603</td>\n",
       "      <td>film mesmerizing beauty creativity. artist's p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19945</td>\n",
       "      <td>Filmfour going lot better little snot film the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20089</td>\n",
       "      <td>60s (1999) D: Mark Piznarski. Josh Hamilton, J...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19381</td>\n",
       "      <td>show suck? Unfortunately, really question, dou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4685</td>\n",
       "      <td>Sometimes want laugh. Don't you? analyzing, cr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23539</td>\n",
       "      <td>anti-bush jokes get really easy do, show like ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20356</td>\n",
       "      <td>others noted, excellent Hammer-style film, see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>5900</td>\n",
       "      <td>almost ideal romantic anime! MUST SEE AGES! En...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>6935</td>\n",
       "      <td>Unfortunately, film long unavailable (as poste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>16838</td>\n",
       "      <td>**1/2 Diane Keaton farce.&lt;br /&gt;&lt;br /&gt;Someone t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>9734</td>\n",
       "      <td>Film looking glass see world new light. Good N...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>18862</td>\n",
       "      <td>empty lack lustre rendition classic novel. wis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>21220</td>\n",
       "      <td>movie good example extreme lack good writers d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>9160</td>\n",
       "      <td>movie really great flick something affects us ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>13274</td>\n",
       "      <td>Darkling interesting entertaining film F. Murr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>5337</td>\n",
       "      <td>Marlon Brando Frank Sinatra HATED film years f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>19197</td>\n",
       "      <td>2004, liked it. became stupid. suggests kids b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>15288</td>\n",
       "      <td>avoid making type film future. film interestin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>2999</td>\n",
       "      <td>Wow... 5 hours Riget. Lars continues great com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>5790</td>\n",
       "      <td>Marvelous James Stewart, Vera Miles vehicle. m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>14570</td>\n",
       "      <td>characters depth-less rip offs. you've seen ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>10232</td>\n",
       "      <td>countless talking-animal films past, majority ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>6911</td>\n",
       "      <td>absurdist dark comedy Belgium. Shot perfectly ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>11510</td>\n",
       "      <td>nice see Suraj Barjatya back best at.A story w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>12907</td>\n",
       "      <td>movie poorly written, poorly acted predictable...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>3679</td>\n",
       "      <td>unpretentious Horror film probably destined be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>546</td>\n",
       "      <td>saw Saving Grace right came video. Since it's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>8664</td>\n",
       "      <td>Taking old collection stories poses challenge ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>5382</td>\n",
       "      <td>movie made want become director, Michelle Rodr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>14732</td>\n",
       "      <td>video thing. think fourth attempt managed watc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>1983</td>\n",
       "      <td>almost typical Lynch. However, makes film slig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>22790</td>\n",
       "      <td>really must caught different film rest comment...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>20009</td>\n",
       "      <td>kid 50's 60's anything connected Disney defini...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>9553</td>\n",
       "      <td>course reading review seen film already. 'Raja...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>16744</td>\n",
       "      <td>read \"There's Girl Soup\" came Peter Sellers's ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>22896</td>\n",
       "      <td>film quite boring. snippets naked flesh tossed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>7334</td>\n",
       "      <td>Although film somewhat filled eighties cheese ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_Number                                               text  polarity\n",
       "0            2148  first think another Disney movie, might good, ...         1\n",
       "1           23577  Put aside Dr. House repeat missed, Desperate H...         0\n",
       "2            1319  big fan Stephen King's work, film made even gr...         1\n",
       "3           13358  watched horrid thing TV. Needless say one movi...         0\n",
       "4            9495  truly enjoyed film. acting terrific plot. Jeff...         1\n",
       "5            2154  memory \"The Last Hunt\" stuck since saw 1956 13...         1\n",
       "6           19880  Shakespeare fan, appreciate Ken Branagh done b...         0\n",
       "7            2073  privilege watching Scarface big screen beautif...         1\n",
       "8           12001  real classic. shipload sailors trying get town...         1\n",
       "9            9373  Serials short subjects originally shown theate...         1\n",
       "10          19704  strange sex comedy there`s little comedy whole...         0\n",
       "11          20033  many problems film, worst continuity; re-editi...         0\n",
       "12          21530  Rosie wasted lot TV time talking Tainos super ...         0\n",
       "13           6972  Man, people got chill. movie artistic genius. ...         1\n",
       "14           5145  great movie could Soylent Green. scenes people...         1\n",
       "15           2317  Wonderful family drama/comedy starring MacClai...         1\n",
       "16           6140  \"Ko tamo peva\" one best films ever saw. tragic...         1\n",
       "17           4585  quite long time life, either like film, liked ...         1\n",
       "18           1673  \"Kolchak\" TV series really didn't fit category...         1\n",
       "19           3930  It's rare find literary work adequately transl...         1\n",
       "20          18860  awful, awful! old room mate used watch junk dr...         0\n",
       "21           3156  mom recently become addicted show, laughing bu...         1\n",
       "22           8187  okay, plain dumb. bad horror/comedy film. read...         1\n",
       "23           1603  film mesmerizing beauty creativity. artist's p...         1\n",
       "24          19945  Filmfour going lot better little snot film the...         0\n",
       "25          20089  60s (1999) D: Mark Piznarski. Josh Hamilton, J...         0\n",
       "26          19381  show suck? Unfortunately, really question, dou...         0\n",
       "27           4685  Sometimes want laugh. Don't you? analyzing, cr...         1\n",
       "28          23539  anti-bush jokes get really easy do, show like ...         0\n",
       "29          20356  others noted, excellent Hammer-style film, see...         0\n",
       "...           ...                                                ...       ...\n",
       "24970        5900  almost ideal romantic anime! MUST SEE AGES! En...         1\n",
       "24971        6935  Unfortunately, film long unavailable (as poste...         1\n",
       "24972       16838  **1/2 Diane Keaton farce.<br /><br />Someone t...         0\n",
       "24973        9734  Film looking glass see world new light. Good N...         1\n",
       "24974       18862  empty lack lustre rendition classic novel. wis...         0\n",
       "24975       21220  movie good example extreme lack good writers d...         0\n",
       "24976        9160  movie really great flick something affects us ...         1\n",
       "24977       13274  Darkling interesting entertaining film F. Murr...         0\n",
       "24978        5337  Marlon Brando Frank Sinatra HATED film years f...         1\n",
       "24979       19197  2004, liked it. became stupid. suggests kids b...         0\n",
       "24980       15288  avoid making type film future. film interestin...         0\n",
       "24981        2999  Wow... 5 hours Riget. Lars continues great com...         1\n",
       "24982        5790  Marvelous James Stewart, Vera Miles vehicle. m...         1\n",
       "24983       14570  characters depth-less rip offs. you've seen ch...         0\n",
       "24984       10232  countless talking-animal films past, majority ...         1\n",
       "24985        6911  absurdist dark comedy Belgium. Shot perfectly ...         1\n",
       "24986       11510  nice see Suraj Barjatya back best at.A story w...         1\n",
       "24987       12907  movie poorly written, poorly acted predictable...         0\n",
       "24988        3679  unpretentious Horror film probably destined be...         1\n",
       "24989         546  saw Saving Grace right came video. Since it's ...         1\n",
       "24990        8664  Taking old collection stories poses challenge ...         1\n",
       "24991        5382  movie made want become director, Michelle Rodr...         1\n",
       "24992       14732  video thing. think fourth attempt managed watc...         0\n",
       "24993        1983  almost typical Lynch. However, makes film slig...         1\n",
       "24994       22790  really must caught different film rest comment...         0\n",
       "24995       20009  kid 50's 60's anything connected Disney defini...         0\n",
       "24996        9553  course reading review seen film already. 'Raja...         1\n",
       "24997       16744  read \"There's Girl Soup\" came Peter Sellers's ...         0\n",
       "24998       22896  film quite boring. snippets naked flesh tossed...         0\n",
       "24999        7334  Although film somewhat filled eighties cheese ...         1\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "train = train.sort_values(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())\n",
    "\n",
    "train['text'] = train['text'].apply(lambda x : cleanSentences(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['polarity'] = train['polarity'].map({1: np.array([1,0]), 0: np.array([0,1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vocab_list = []\n",
    "#def vocab(sentence):\n",
    "#    with open(\"imdb_dataset3.txt\", \"a\") as myfile:\n",
    "#        myfile.write(str(sentence)+'\\n')\n",
    "\n",
    "#train['text'].apply(lambda x : vocab(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "#sentences = gensim.models.word2vec.LineSentence(\"imdb_dataset3.txt\")\n",
    "#print(\"sentences\")\n",
    "#model = gensim.models.word2vec.Word2Vec(sentences,sample = 0.001, sg = 1, workers = 4, negative = 20, window = 10, seed = 1, alpha = 0.025, min_count = 0, min_alpha = 0.0001, size = 100)\n",
    "#print(\"model\")\n",
    "#word_vectors = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word_vectors.save('imdb_wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors = gensim.models.Word2Vec.load('imdb_wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordVectors = []\n",
    "for word in word_vectors.wv.index2word:\n",
    "    wordVectors.append(word_vectors.wv[word])\n",
    "wordVectors = np.array(wordVectors)\n",
    "wordsList = word_vectors.wv.index2word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie',\n",
       " 'film',\n",
       " 'one',\n",
       " 'like',\n",
       " 'its',\n",
       " 'good',\n",
       " 'it',\n",
       " 'the',\n",
       " 'even',\n",
       " 'would',\n",
       " 'time',\n",
       " 'really',\n",
       " 'story',\n",
       " 'see',\n",
       " 'much',\n",
       " 'well',\n",
       " 'get',\n",
       " 'also',\n",
       " 'bad',\n",
       " 'people',\n",
       " 'great',\n",
       " 'first',\n",
       " 'dont',\n",
       " 'made',\n",
       " 'movies',\n",
       " 'way',\n",
       " 'films',\n",
       " 'make',\n",
       " 'could',\n",
       " 'characters',\n",
       " 'think',\n",
       " 'watch',\n",
       " 'two',\n",
       " 'many',\n",
       " 'seen',\n",
       " 'character',\n",
       " 'never',\n",
       " 'little',\n",
       " 'acting',\n",
       " 'plot',\n",
       " 'best',\n",
       " 'love',\n",
       " 'life',\n",
       " 'know',\n",
       " 'show',\n",
       " 'ever',\n",
       " 'this',\n",
       " 'better',\n",
       " 'still',\n",
       " 'end',\n",
       " 'say',\n",
       " 'scene',\n",
       " 'man',\n",
       " 'i',\n",
       " 'scenes',\n",
       " 'go',\n",
       " 'something',\n",
       " 'back',\n",
       " 'im',\n",
       " 'doesnt',\n",
       " 'watching',\n",
       " 'real',\n",
       " 'years',\n",
       " 'though',\n",
       " 'thing',\n",
       " 'actors',\n",
       " 'didnt',\n",
       " 'another',\n",
       " 'new',\n",
       " 'nothing',\n",
       " 'actually',\n",
       " 'work',\n",
       " 'funny',\n",
       " 'makes',\n",
       " 'find',\n",
       " 'look',\n",
       " 'old',\n",
       " 'going',\n",
       " 'us',\n",
       " 'every',\n",
       " 'lot',\n",
       " 'part',\n",
       " 'director',\n",
       " 'cant',\n",
       " 'thats',\n",
       " 'cast',\n",
       " 'quite',\n",
       " 'want',\n",
       " 'and',\n",
       " 'things',\n",
       " 'all',\n",
       " 'pretty',\n",
       " 'seems',\n",
       " 'young',\n",
       " 'got',\n",
       " 'around',\n",
       " 'world',\n",
       " 'fact',\n",
       " 'however',\n",
       " 'take',\n",
       " 'enough',\n",
       " 'give',\n",
       " 'may',\n",
       " 'ive',\n",
       " 'big',\n",
       " 'horror',\n",
       " 'original',\n",
       " 'thought',\n",
       " 'series',\n",
       " 'that',\n",
       " 'without',\n",
       " 'gets',\n",
       " 'right',\n",
       " 'always',\n",
       " 'long',\n",
       " 'times',\n",
       " 'isnt',\n",
       " 'come',\n",
       " 'saw',\n",
       " 'point',\n",
       " 'role',\n",
       " 'almost',\n",
       " 'interesting',\n",
       " 'action',\n",
       " 'least',\n",
       " 'theres',\n",
       " 'comedy',\n",
       " 'whole',\n",
       " 'must',\n",
       " 'family',\n",
       " 'bit',\n",
       " 'done',\n",
       " 'music',\n",
       " 'script',\n",
       " 'me',\n",
       " 'minutes',\n",
       " 'anything',\n",
       " 'last',\n",
       " 'hes',\n",
       " 'might',\n",
       " 'guy',\n",
       " 'since',\n",
       " 'performance',\n",
       " 'feel',\n",
       " 'is',\n",
       " 'far',\n",
       " 'probably',\n",
       " 'kind',\n",
       " 'rather',\n",
       " 'away',\n",
       " 'yet',\n",
       " 'worst',\n",
       " 'sure',\n",
       " 'fun',\n",
       " 'tv',\n",
       " 'girl',\n",
       " 'woman',\n",
       " 'making',\n",
       " 'in',\n",
       " 'anyone',\n",
       " 'found',\n",
       " 'played',\n",
       " 'although',\n",
       " 'believe',\n",
       " 'day',\n",
       " 'course',\n",
       " 'comes',\n",
       " 'them',\n",
       " 'trying',\n",
       " 'especially',\n",
       " 'goes',\n",
       " 'there',\n",
       " 'shows',\n",
       " 'hard',\n",
       " 'him',\n",
       " 'looks',\n",
       " 'different',\n",
       " 'here',\n",
       " 'place',\n",
       " 'put',\n",
       " 'wasnt',\n",
       " 'book',\n",
       " 'ending',\n",
       " 'money',\n",
       " 'sense',\n",
       " 'reason',\n",
       " 'maybe',\n",
       " 'everything',\n",
       " 'true',\n",
       " 'set',\n",
       " 'screen',\n",
       " 'worth',\n",
       " 'main',\n",
       " 'looking',\n",
       " 'job',\n",
       " 'someone',\n",
       " 'watched',\n",
       " 'plays',\n",
       " '2',\n",
       " 'actor',\n",
       " 'dvd',\n",
       " 'together',\n",
       " 'three',\n",
       " 'said',\n",
       " 'seem',\n",
       " 'later',\n",
       " '10',\n",
       " 'instead',\n",
       " 'takes',\n",
       " 'play',\n",
       " 'beautiful',\n",
       " 'again',\n",
       " 'effects',\n",
       " 'john',\n",
       " 'version',\n",
       " 'audience',\n",
       " 'everyone',\n",
       " 'left',\n",
       " 'seeing',\n",
       " 'you',\n",
       " 'night',\n",
       " 'special',\n",
       " 'house',\n",
       " 'excellent',\n",
       " 'on',\n",
       " 'idea',\n",
       " 'american',\n",
       " 'a',\n",
       " 'out',\n",
       " 'but',\n",
       " 'nice',\n",
       " 'shot',\n",
       " 'wife',\n",
       " 'simply',\n",
       " 'youre',\n",
       " 'read',\n",
       " 'else',\n",
       " 'high',\n",
       " 'less',\n",
       " 'kids',\n",
       " 'black',\n",
       " 'help',\n",
       " 'completely',\n",
       " 'war',\n",
       " 'second',\n",
       " 'poor',\n",
       " 'fan',\n",
       " 'star',\n",
       " 'so',\n",
       " 'year',\n",
       " 'death',\n",
       " 'used',\n",
       " 'given',\n",
       " 'father',\n",
       " 'either',\n",
       " 'friends',\n",
       " 'mind',\n",
       " 'home',\n",
       " 'try',\n",
       " 'men',\n",
       " 'enjoy',\n",
       " 'performances',\n",
       " 'classic',\n",
       " 'rest',\n",
       " 'need',\n",
       " 'short',\n",
       " 'use',\n",
       " 'boring',\n",
       " 'wrong',\n",
       " 'along',\n",
       " 'hollywood',\n",
       " 'truly',\n",
       " 'her',\n",
       " 'dead',\n",
       " 'half',\n",
       " 'production',\n",
       " 'line',\n",
       " 'tell',\n",
       " 'women',\n",
       " 'not',\n",
       " 'remember',\n",
       " 'next',\n",
       " 'couple',\n",
       " 'start',\n",
       " 'came',\n",
       " 'recommend',\n",
       " 'perhaps',\n",
       " 'others',\n",
       " 'stupid',\n",
       " 'moments',\n",
       " 'wonderful',\n",
       " 'awful',\n",
       " 'understand',\n",
       " 'full',\n",
       " 'let',\n",
       " 'mean',\n",
       " 'episode',\n",
       " 'getting',\n",
       " 'terrible',\n",
       " 'stars',\n",
       " 'camera',\n",
       " 'playing',\n",
       " 'keep',\n",
       " 'often',\n",
       " 'small',\n",
       " 'sex',\n",
       " 'definitely',\n",
       " 'video',\n",
       " 'gives',\n",
       " 'as',\n",
       " 'perfect',\n",
       " 'face',\n",
       " 'early',\n",
       " 'up',\n",
       " 'name',\n",
       " 'become',\n",
       " 'too',\n",
       " 'school',\n",
       " 'lines',\n",
       " 'finally',\n",
       " 'human',\n",
       " 'felt',\n",
       " 'person',\n",
       " 'dialogue',\n",
       " 'supposed',\n",
       " 'lost',\n",
       " 'piece',\n",
       " 'liked',\n",
       " 'couldnt',\n",
       " 'case',\n",
       " 'top',\n",
       " 'yes',\n",
       " 'absolutely',\n",
       " 'written',\n",
       " 'now',\n",
       " 'head',\n",
       " 'title',\n",
       " 'live',\n",
       " 'budget',\n",
       " 'entire',\n",
       " 'went',\n",
       " 'certainly',\n",
       " 'waste',\n",
       " 'sort',\n",
       " 'picture',\n",
       " 'style',\n",
       " 'shes',\n",
       " 'worse',\n",
       " 'problem',\n",
       " 'hope',\n",
       " 'cinema',\n",
       " 'if',\n",
       " 'evil',\n",
       " 'entertaining',\n",
       " 'overall',\n",
       " 'several',\n",
       " 'loved',\n",
       " 'fans',\n",
       " 'id',\n",
       " 'beginning',\n",
       " 'mr',\n",
       " '3',\n",
       " 'boy',\n",
       " 'becomes',\n",
       " 'care',\n",
       " 'already',\n",
       " 'white',\n",
       " 'lives',\n",
       " 'seemed',\n",
       " 'throughout',\n",
       " 'based',\n",
       " 'example',\n",
       " 'direction',\n",
       " 'mother',\n",
       " 'despite',\n",
       " 'killer',\n",
       " 'guys',\n",
       " 'oh',\n",
       " 'dark',\n",
       " 'wanted',\n",
       " 'unfortunately',\n",
       " 'friend',\n",
       " '1',\n",
       " 'final',\n",
       " 'children',\n",
       " 'turn',\n",
       " 'fine',\n",
       " 'drama',\n",
       " 'laugh',\n",
       " 'totally',\n",
       " 'amazing',\n",
       " 'wont',\n",
       " 'girls',\n",
       " 'wants',\n",
       " 'guess',\n",
       " 'history',\n",
       " 'humor',\n",
       " 'sound',\n",
       " 'lead',\n",
       " 'youll',\n",
       " 'writing',\n",
       " 'days',\n",
       " 'works',\n",
       " 'low',\n",
       " 'tries',\n",
       " 'called',\n",
       " 'past',\n",
       " 'michael',\n",
       " 'quality',\n",
       " 'behind',\n",
       " 'turns',\n",
       " 'enjoyed',\n",
       " 'able',\n",
       " 'theyre',\n",
       " 'game',\n",
       " 'act',\n",
       " 'with',\n",
       " 'favorite',\n",
       " 'son',\n",
       " 'starts',\n",
       " 'gave',\n",
       " 'kill',\n",
       " 'flick',\n",
       " 'eyes',\n",
       " 'sometimes',\n",
       " 'side',\n",
       " 'viewer',\n",
       " 'town',\n",
       " 'horrible',\n",
       " 'ones',\n",
       " 'for',\n",
       " 'soon',\n",
       " 'car',\n",
       " 'parts',\n",
       " 'actress',\n",
       " 'child',\n",
       " 'expect',\n",
       " 'brilliant',\n",
       " 'what',\n",
       " 'heart',\n",
       " 'genre',\n",
       " 'art',\n",
       " 'stuff',\n",
       " 'stories',\n",
       " 'obviously',\n",
       " 'thinking',\n",
       " 'directed',\n",
       " 'to',\n",
       " 'late',\n",
       " 'ill',\n",
       " 'feeling',\n",
       " 'decent',\n",
       " 'run',\n",
       " 'blood',\n",
       " 'do',\n",
       " 'highly',\n",
       " 'city',\n",
       " 'etc',\n",
       " 'close',\n",
       " 'fight',\n",
       " 'hand',\n",
       " 'says',\n",
       " 'heard',\n",
       " 'matter',\n",
       " 'roles',\n",
       " 'took',\n",
       " 'killed',\n",
       " 'except',\n",
       " 'moment',\n",
       " 'cannot',\n",
       " 'leave',\n",
       " 'kid',\n",
       " 'hell',\n",
       " 'was',\n",
       " 'police',\n",
       " 'anyway',\n",
       " 'happens',\n",
       " 'wouldnt',\n",
       " 'strong',\n",
       " 'hour',\n",
       " 'happened',\n",
       " 'extremely',\n",
       " 'involved',\n",
       " 'chance',\n",
       " 'obvious',\n",
       " 'particularly',\n",
       " 'lack',\n",
       " 'experience',\n",
       " 'violence',\n",
       " 'attempt',\n",
       " 'told',\n",
       " 'living',\n",
       " 'then',\n",
       " 'james',\n",
       " 'no',\n",
       " 'alone',\n",
       " 'be',\n",
       " 'happen',\n",
       " 'wonder',\n",
       " 'age',\n",
       " 'murder',\n",
       " 'complete',\n",
       " 'voice',\n",
       " 'including',\n",
       " 'ago',\n",
       " 'daughter',\n",
       " 'coming',\n",
       " 'save',\n",
       " 'god',\n",
       " 'please',\n",
       " 'group',\n",
       " 'interest',\n",
       " 'off',\n",
       " 'type',\n",
       " 'more',\n",
       " 'score',\n",
       " 'none',\n",
       " 'ok',\n",
       " 'looked',\n",
       " 'simple',\n",
       " 'number',\n",
       " 'exactly',\n",
       " 'slow',\n",
       " 'shown',\n",
       " 'brother',\n",
       " 'possible',\n",
       " 'crap',\n",
       " 'lets',\n",
       " 'annoying',\n",
       " 'career',\n",
       " 'taken',\n",
       " 'whose',\n",
       " 'serious',\n",
       " 'usually',\n",
       " 'which',\n",
       " 'sad',\n",
       " 'ends',\n",
       " 'cinematography',\n",
       " 'hours',\n",
       " 'stop',\n",
       " 'song',\n",
       " 'seriously',\n",
       " 'across',\n",
       " 'david',\n",
       " 'scary',\n",
       " 'released',\n",
       " 'who',\n",
       " 'running',\n",
       " 'gore',\n",
       " 'musical',\n",
       " 'today',\n",
       " 'opening',\n",
       " 'usual',\n",
       " 'somewhat',\n",
       " 'known',\n",
       " 'hilarious',\n",
       " 'started',\n",
       " 'reality',\n",
       " 'relationship',\n",
       " 'hit',\n",
       " 'ridiculous',\n",
       " 'jokes',\n",
       " 'finds',\n",
       " 'wish',\n",
       " 'change',\n",
       " 'order',\n",
       " 'huge',\n",
       " 'cool',\n",
       " 'shots',\n",
       " 'saying',\n",
       " 'episodes',\n",
       " 'opinion',\n",
       " 'cut',\n",
       " 'body',\n",
       " 'english',\n",
       " 'novel',\n",
       " 'mostly',\n",
       " 'robert',\n",
       " 'taking',\n",
       " 'major',\n",
       " '4',\n",
       " 'talking',\n",
       " 'female',\n",
       " 'of',\n",
       " 'call',\n",
       " 'hero',\n",
       " 'power',\n",
       " 'strange',\n",
       " 'view',\n",
       " 'apparently',\n",
       " 'level',\n",
       " '5',\n",
       " 'disappointed',\n",
       " 'directors',\n",
       " 'talent',\n",
       " 'happy',\n",
       " 'documentary',\n",
       " 'due',\n",
       " 'important',\n",
       " 'events',\n",
       " 'husband',\n",
       " 'knows',\n",
       " 'room',\n",
       " 'basically',\n",
       " 'songs',\n",
       " 'supporting',\n",
       " 'clearly',\n",
       " 'knew',\n",
       " 'turned',\n",
       " 'king',\n",
       " 'rating',\n",
       " 'attention',\n",
       " 'easily',\n",
       " 'arent',\n",
       " 'british',\n",
       " 'problems',\n",
       " 'tells',\n",
       " 'single',\n",
       " 'future',\n",
       " 'local',\n",
       " 'television',\n",
       " 'silly',\n",
       " 'word',\n",
       " 'why',\n",
       " 'words',\n",
       " 'bring',\n",
       " 'cheap',\n",
       " 'sequence',\n",
       " 'country',\n",
       " 'four',\n",
       " 'light',\n",
       " 'whats',\n",
       " 'modern',\n",
       " 'beyond',\n",
       " 'earth',\n",
       " 'sets',\n",
       " 'jack',\n",
       " 'miss',\n",
       " 'whether',\n",
       " 'falls',\n",
       " 'viewers',\n",
       " 'five',\n",
       " 'entertainment',\n",
       " 'similar',\n",
       " 'paul',\n",
       " 'or',\n",
       " 'review',\n",
       " 'before',\n",
       " 'predictable',\n",
       " 'needs',\n",
       " 'appears',\n",
       " 'about',\n",
       " 'upon',\n",
       " 'enjoyable',\n",
       " 'romantic',\n",
       " 'giving',\n",
       " 'other',\n",
       " 'comic',\n",
       " 'richard',\n",
       " 'george',\n",
       " 'talk',\n",
       " 'within',\n",
       " 'storyline',\n",
       " 'message',\n",
       " 'havent',\n",
       " 'animation',\n",
       " 'theater',\n",
       " 'feels',\n",
       " 'mention',\n",
       " 'bunch',\n",
       " 'nearly',\n",
       " 'lady',\n",
       " 'rock',\n",
       " 'add',\n",
       " 'sequel',\n",
       " 'points',\n",
       " 'moving',\n",
       " 'mystery',\n",
       " 'lots',\n",
       " 'surprised',\n",
       " 'dull',\n",
       " 'ways',\n",
       " 'theme',\n",
       " 'begins',\n",
       " 'using',\n",
       " 'actual',\n",
       " 'middle',\n",
       " 'ten',\n",
       " 'named',\n",
       " 'effort',\n",
       " 'fantastic',\n",
       " 'writer',\n",
       " 'thriller',\n",
       " 'york',\n",
       " 'comments',\n",
       " 'among',\n",
       " 'easy',\n",
       " 'elements',\n",
       " 'stay',\n",
       " 'showing',\n",
       " 'typical',\n",
       " 'team',\n",
       " 'clear',\n",
       " 'release',\n",
       " 'tried',\n",
       " 'certain',\n",
       " 'avoid',\n",
       " 'dialog',\n",
       " 'fall',\n",
       " 'french',\n",
       " 'parents',\n",
       " 'were',\n",
       " 'tale',\n",
       " 'near',\n",
       " 'hate',\n",
       " 'soundtrack',\n",
       " 'means',\n",
       " 'famous',\n",
       " 'season',\n",
       " 'straight',\n",
       " 'editing',\n",
       " 'somehow',\n",
       " 'sorry',\n",
       " 'general',\n",
       " 'leads',\n",
       " 'class',\n",
       " 'working',\n",
       " 'form',\n",
       " 'material',\n",
       " 'peter',\n",
       " 'buy',\n",
       " 'doubt',\n",
       " 'red',\n",
       " 'check',\n",
       " 'kept',\n",
       " 'greatest',\n",
       " 'sister',\n",
       " 'filmed',\n",
       " 'figure',\n",
       " 'oscar',\n",
       " 'weak',\n",
       " 'viewing',\n",
       " 'tom',\n",
       " 'period',\n",
       " 'feature',\n",
       " 'brought',\n",
       " 'gone',\n",
       " 'eye',\n",
       " 'hear',\n",
       " 'particular',\n",
       " 'imagine',\n",
       " 'whos',\n",
       " 'realistic',\n",
       " 'did',\n",
       " 'atmosphere',\n",
       " 'fast',\n",
       " 'follow',\n",
       " 'learn',\n",
       " 'move',\n",
       " 'reviews',\n",
       " 'lame',\n",
       " 'sequences',\n",
       " 'eventually',\n",
       " 'youve',\n",
       " 'indeed',\n",
       " 'forget',\n",
       " 'die',\n",
       " 'deal',\n",
       " 'premise',\n",
       " 'space',\n",
       " 'dance',\n",
       " 'decided',\n",
       " 'believable',\n",
       " 'crime',\n",
       " 'possibly',\n",
       " 'lee',\n",
       " 'wait',\n",
       " 'surprise',\n",
       " 'third',\n",
       " 'expected',\n",
       " 'whatever',\n",
       " 'became',\n",
       " 'de',\n",
       " 'suspense',\n",
       " 'nature',\n",
       " 'stand',\n",
       " 'difficult',\n",
       " 'japanese',\n",
       " 'zombie',\n",
       " 'writers',\n",
       " 'sit',\n",
       " 'truth',\n",
       " 'poorly',\n",
       " 'okay',\n",
       " 'sexual',\n",
       " 'subject',\n",
       " '80s',\n",
       " 'average',\n",
       " 'leaves',\n",
       " 'screenplay',\n",
       " 'rent',\n",
       " 'stage',\n",
       " 'my',\n",
       " 'killing',\n",
       " 'needed',\n",
       " 'begin',\n",
       " 'romance',\n",
       " 'filmmakers',\n",
       " 'reading',\n",
       " 'question',\n",
       " 'note',\n",
       " 'meet',\n",
       " 'dr',\n",
       " 'situation',\n",
       " 'boys',\n",
       " 'meets',\n",
       " 'memorable',\n",
       " 'street',\n",
       " 'superb',\n",
       " 'shame',\n",
       " 'down',\n",
       " 'otherwise',\n",
       " 'credits',\n",
       " 'joe',\n",
       " 'forced',\n",
       " 'earlier',\n",
       " 'minute',\n",
       " 'baby',\n",
       " 'realize',\n",
       " 'emotional',\n",
       " 'at',\n",
       " 'unless',\n",
       " 'footage',\n",
       " 'weird',\n",
       " 'older',\n",
       " 'beauty',\n",
       " 'interested',\n",
       " 'society',\n",
       " 'disney',\n",
       " 'write',\n",
       " 'keeps',\n",
       " 'badly',\n",
       " 'laughs',\n",
       " 'comment',\n",
       " 'dramatic',\n",
       " 'features',\n",
       " 'dog',\n",
       " 'ask',\n",
       " 'hot',\n",
       " 'towards',\n",
       " 'sounds',\n",
       " 'crazy',\n",
       " 'america',\n",
       " 'mess',\n",
       " 'development',\n",
       " 'quickly',\n",
       " 'total',\n",
       " 'perfectly',\n",
       " 'previous',\n",
       " 'brings',\n",
       " 'result',\n",
       " 'directing',\n",
       " 'male',\n",
       " 'free',\n",
       " 'are',\n",
       " 'worked',\n",
       " 'unique',\n",
       " 'plenty',\n",
       " 'personal',\n",
       " 'plus',\n",
       " 'effect',\n",
       " 'incredibly',\n",
       " 'creepy',\n",
       " 'hands',\n",
       " 'imdb',\n",
       " 'cheesy',\n",
       " 'deep',\n",
       " 'mark',\n",
       " 'return',\n",
       " 'admit',\n",
       " 'himself',\n",
       " 'apart',\n",
       " 'appear',\n",
       " 'b',\n",
       " 'brothers',\n",
       " 'setting',\n",
       " 'meant',\n",
       " '20',\n",
       " 'open',\n",
       " 'leading',\n",
       " 'dream',\n",
       " 'hardly',\n",
       " 'casting',\n",
       " 'background',\n",
       " 'christmas',\n",
       " 'remake',\n",
       " 'potential',\n",
       " 'powerful',\n",
       " 'various',\n",
       " 'create',\n",
       " 'forward',\n",
       " 'fails',\n",
       " 'scifi',\n",
       " 'business',\n",
       " 'bill',\n",
       " 'battle',\n",
       " 'inside',\n",
       " 'monster',\n",
       " 'joke',\n",
       " 'portrayed',\n",
       " 'masterpiece',\n",
       " '70s',\n",
       " 'outside',\n",
       " 'fire',\n",
       " 'ideas',\n",
       " 'missing',\n",
       " 'jane',\n",
       " 'reasons',\n",
       " 'twist',\n",
       " 'deserves',\n",
       " 'while',\n",
       " 'match',\n",
       " 'expecting',\n",
       " 'fantasy',\n",
       " 'secret',\n",
       " 'dumb',\n",
       " 'fairly',\n",
       " 'la',\n",
       " 'present',\n",
       " 'air',\n",
       " 'manages',\n",
       " 'attempts',\n",
       " 'political',\n",
       " 'fighting',\n",
       " 'gay',\n",
       " 'success',\n",
       " 'pay',\n",
       " 'recently',\n",
       " 'break',\n",
       " 'unlike',\n",
       " 'ben',\n",
       " 'front',\n",
       " 'married',\n",
       " 'nudity',\n",
       " 'william',\n",
       " 'box',\n",
       " 'rich',\n",
       " 'copy',\n",
       " 'acted',\n",
       " 'agree',\n",
       " 'telling',\n",
       " 'spoilers',\n",
       " 'villain',\n",
       " 'cute',\n",
       " 'western',\n",
       " 'following',\n",
       " 'sadly',\n",
       " 'talented',\n",
       " 'missed',\n",
       " 'plain',\n",
       " 'girlfriend',\n",
       " 'pure',\n",
       " 'era',\n",
       " 'incredible',\n",
       " 'doctor',\n",
       " 'odd',\n",
       " 'wasted',\n",
       " 'cop',\n",
       " 'caught',\n",
       " 'crew',\n",
       " 'flat',\n",
       " 'decides',\n",
       " 'mentioned',\n",
       " 'members',\n",
       " 'social',\n",
       " 'large',\n",
       " 'itself',\n",
       " 'considering',\n",
       " 'ended',\n",
       " 'sees',\n",
       " 'pace',\n",
       " 'public',\n",
       " 'waiting',\n",
       " 'over',\n",
       " 'uses',\n",
       " 'neither',\n",
       " 'popular',\n",
       " 'sweet',\n",
       " 'hold',\n",
       " 'slightly',\n",
       " 'wrote',\n",
       " 'office',\n",
       " 'list',\n",
       " 'suddenly',\n",
       " 'compared',\n",
       " 'spent',\n",
       " 'rate',\n",
       " 'tension',\n",
       " 'revenge',\n",
       " 'entirely',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[  53  107    7    0  473  963   88 3568    0    0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "maxSeqLength = 10 #Maximum length of sentence\n",
    "numDimensions = 300 #Dimensions for each word vector\n",
    "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "firstSentence[0] = wordsList.index(\"i\")\n",
    "firstSentence[1] = wordsList.index(\"thought\")\n",
    "firstSentence[2] = wordsList.index(\"the\")\n",
    "firstSentence[3] = wordsList.index(\"movie\")\n",
    "firstSentence[4] = wordsList.index(\"was\")\n",
    "firstSentence[5] = wordsList.index(\"incredible\")\n",
    "firstSentence[6] = wordsList.index(\"and\")\n",
    "firstSentence[7] = wordsList.index(\"inspiring\")\n",
    "\n",
    "print(firstSentence.shape)\n",
    "print(firstSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors,firstSentence).eval().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxSeqLength = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111419"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#numFiles = len(train)\n",
    "#maxSeqLength = 250\n",
    "#ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "#fileCounter = 0\n",
    "#indexCounter = 0\n",
    "\n",
    "#for line in train['text']:\n",
    "#    cleanedLine = cleanSentences(str(line))\n",
    "#    split = cleanedLine.split()\n",
    "#    indexCounter = 0\n",
    "    \n",
    "#    for word in split:\n",
    "       # print(indexCounter)\n",
    "#        try:\n",
    "#            ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#        except ValueError:\n",
    "#            ids[fileCounter][indexCounter] = len(wordsList)-2 #Vector for unkown words\n",
    "#        indexCounter = indexCounter + 1\n",
    "#        if indexCounter >= maxSeqLength:\n",
    "#            break\n",
    "#    fileCounter = fileCounter + 1 \n",
    "#    print(fileCounter/numFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save('imdb_ids',ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.load('imdb_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(ids,np.array(list (train['polarity'])), test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainBatch(j):\n",
    "    i = j*batchSize\n",
    "    arr = X_train[i:i+batchSize]\n",
    "    labels = y_train[i:i+batchSize]\n",
    "    #print(i)\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTestBatch(j):\n",
    "    i = j*batchSize\n",
    "    arr = X_test[i:i+batchSize]\n",
    "    labels =   y_test[i:i+batchSize]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 100\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "epochs = 1\n",
    "maxSeqLength = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordVectors.shape\n",
    "wordVectors = tf.convert_to_tensor(wordVectors, dtype=tf.float32)\n",
    "type(wordVectors)\n",
    "np.array([batchSize, maxSeqLength, numDimensions]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = tf.placeholder(shape = (batchSize,maxSeqLength,numDimensions), dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw_cell3 = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.BasicLSTMCell(lstmUnits, state_is_tuple=True) for _ in range(2)])\n",
    "bw_cell3 = tf.nn.rnn_cell.MultiRNNCell([ tf.nn.rnn_cell.BasicLSTMCell(lstmUnits, state_is_tuple=True) for _ in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs,value2 = tf.nn.bidirectional_dynamic_rnn(fw_cell3, bw_cell3,data,dtype=tf.float32,scope='biLSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = tf.concat(outputs, 2)\n",
    "value2 = tf.concat(value2, 3)\n",
    "\n",
    "    #print(sess.run(value3,{input_data : x, labels : y}).shape)\n",
    "    \n",
    "    #print((sess.run(tf.transpose(value, [1, 0, 2]),{input_data : x, labels : y})).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#value, _ = tf.nn.dynamic_rnn(rnn_cell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits*2, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(outputs, [1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "#with tf.Session() as sess:\n",
    "#    sess.run(tf.global_variables_initializer())\n",
    "#    x, y = getTrainBatch(1)\n",
    "#    print((np.array(sess.run(value2[0][0],{input_data : x, labels : y}))).shape)\n",
    "#    print((np.array(sess.run(outputs,{input_data : x, labels : y}))).shape)\n",
    "#    print((np.array(sess.run(last,{input_data : x, labels : y}))).shape)\n",
    "\n",
    "prediction = (tf.matmul(value2[0][0], weight) + bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "0.0\n",
      "0.5\n",
      "1.0\n",
      "1.5\n",
      "2.0\n",
      "2.5\n",
      "3.0\n",
      "3.5\n",
      "4.0\n",
      "4.5\n",
      "5.0\n",
      "5.5\n",
      "6.0\n",
      "6.5\n",
      "7.0\n",
      "7.5\n",
      "8.0\n",
      "8.5\n",
      "9.0\n",
      "9.5\n",
      "10.0\n",
      "10.5\n",
      "11.0\n",
      "11.5\n",
      "12.0\n",
      "12.5\n",
      "13.0\n",
      "13.5\n",
      "14.0\n",
      "14.5\n",
      "15.0\n",
      "15.5\n",
      "16.0\n",
      "16.5\n",
      "17.0\n",
      "17.5\n",
      "18.0\n",
      "18.5\n",
      "19.0\n",
      "19.5\n",
      "20.0\n",
      "20.5\n",
      "21.0\n",
      "21.5\n",
      "22.0\n",
      "22.5\n",
      "23.0\n",
      "23.5\n",
      "24.0\n",
      "24.5\n",
      "25.0\n",
      "saved to models/pretrained_lstm.ckpt-0\n",
      "25.5\n",
      "26.0\n",
      "26.5\n",
      "27.0\n",
      "27.5\n",
      "28.0\n",
      "28.5\n",
      "29.0\n",
      "29.5\n",
      "30.0\n",
      "30.5\n",
      "31.0\n",
      "31.5\n",
      "32.0\n",
      "32.5\n",
      "33.0\n",
      "33.5\n",
      "34.0\n",
      "34.5\n",
      "35.0\n",
      "35.5\n",
      "36.0\n",
      "36.5\n",
      "37.0\n",
      "37.5\n",
      "38.0\n",
      "38.5\n",
      "39.0\n",
      "39.5\n",
      "40.0\n",
      "40.5\n",
      "41.0\n",
      "41.5\n",
      "42.0\n",
      "42.5\n",
      "43.0\n",
      "43.5\n",
      "44.0\n",
      "44.5\n",
      "45.0\n",
      "45.5\n",
      "46.0\n",
      "46.5\n",
      "47.0\n",
      "47.5\n",
      "48.0\n",
      "48.5\n",
      "49.0\n",
      "49.5\n",
      "50.0\n",
      "saved to models/pretrained_lstm.ckpt-0\n",
      "50.5\n",
      "51.0\n",
      "51.5\n",
      "52.0\n",
      "52.5\n",
      "53.0\n",
      "53.5\n",
      "54.0\n",
      "54.5\n",
      "55.0\n",
      "55.5\n",
      "56.0\n",
      "56.5\n",
      "57.0\n",
      "57.5\n",
      "58.0\n",
      "58.5\n",
      "59.0\n",
      "59.5\n",
      "60.0\n",
      "60.5\n",
      "61.0\n",
      "61.5\n",
      "62.0\n",
      "62.5\n",
      "63.0\n",
      "63.5\n",
      "64.0\n",
      "64.5\n",
      "65.0\n",
      "65.5\n",
      "66.0\n",
      "66.5\n",
      "67.0\n",
      "67.5\n",
      "68.0\n",
      "68.5\n",
      "69.0\n",
      "69.5\n",
      "70.0\n",
      "70.5\n",
      "71.0\n",
      "71.5\n",
      "72.0\n",
      "72.5\n",
      "73.0\n",
      "73.5\n",
      "74.0\n",
      "74.5\n",
      "75.0\n",
      "saved to models/pretrained_lstm.ckpt-0\n",
      "75.5\n",
      "76.0\n",
      "76.5\n",
      "77.0\n",
      "77.5\n",
      "78.0\n",
      "78.5\n",
      "79.0\n",
      "79.5\n",
      "80.0\n",
      "80.5\n",
      "81.0\n",
      "81.5\n",
      "82.0\n",
      "82.5\n",
      "83.0\n",
      "83.5\n",
      "84.0\n",
      "84.5\n",
      "85.0\n",
      "85.5\n",
      "86.0\n",
      "86.5\n",
      "87.0\n",
      "87.5\n",
      "88.0\n",
      "88.5\n",
      "89.0\n",
      "89.5\n",
      "90.0\n",
      "90.5\n",
      "91.0\n",
      "91.5\n",
      "92.0\n",
      "92.5\n",
      "93.0\n",
      "93.5\n",
      "94.0\n",
      "94.5\n",
      "95.0\n",
      "95.5\n",
      "96.0\n",
      "96.5\n",
      "97.0\n",
      "97.5\n",
      "98.0\n",
      "98.5\n",
      "99.0\n",
      "99.5\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"epoch:  \"+str(i))\n",
    "    #Next Batch of reviews\n",
    "    for j in range(len(X_train)//batchSize):\n",
    "        nextBatch, nextBatchLabels = getTrainBatch(j);\n",
    "        print(j/2)\n",
    "        sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "\n",
    "    #Write summary to Tensorboard\n",
    "        if (j % 5 == 0):\n",
    "            summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "            writer.add_summary(summary, j)\n",
    "\n",
    "        #Save the network every 10,000 training iterations\n",
    "        if (j % 50 == 0 and j != 0):\n",
    "            save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "            print(\"saved to %s\" % save_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 83.9999973774\n",
      "Accuracy for this batch: 83.9999973774\n",
      "Accuracy for this batch: 81.0000002384\n",
      "Accuracy for this batch: 83.9999973774\n",
      "Accuracy for this batch: 82.9999983311\n",
      "Accuracy for this batch: 81.9999992847\n",
      "Accuracy for this batch: 85.0000023842\n",
      "Accuracy for this batch: 88.9999985695\n",
      "Accuracy for this batch: 81.9999992847\n",
      "Accuracy for this batch: 83.9999973774\n",
      "Accuracy for this batch: 82.9999983311\n",
      "Accuracy for this batch: 88.9999985695\n",
      "Accuracy for this batch: 85.0000023842\n",
      "Accuracy for this batch: 86.0000014305\n",
      "Accuracy for this batch: 80.0000011921\n",
      "Accuracy for this batch: 86.0000014305\n",
      "Accuracy for this batch: 83.9999973774\n",
      "Accuracy for this batch: 77.999997139\n",
      "Accuracy for this batch: 82.9999983311\n",
      "Accuracy for this batch: 81.0000002384\n",
      "Accuracy for this batch: 82.9999983311\n",
      "Accuracy for this batch: 79.0000021458\n",
      "Accuracy for this batch: 80.0000011921\n",
      "Accuracy for this batch: 86.0000014305\n",
      "Accuracy for this batch: 80.0000011921\n",
      "Accuracy for this batch: 88.9999985695\n",
      "Accuracy for this batch: 85.0000023842\n",
      "Accuracy for this batch: 83.9999973774\n",
      "Accuracy for this batch: 87.0000004768\n",
      "Accuracy for this batch: 81.0000002384\n",
      "Accuracy for this batch: 86.0000014305\n",
      "Accuracy for this batch: 87.0000004768\n",
      "Accuracy for this batch: 76.9999980927\n",
      "Accuracy for this batch: 81.0000002384\n",
      "Accuracy for this batch: 87.0000004768\n",
      "Accuracy for this batch: 86.0000014305\n",
      "Accuracy for this batch: 81.9999992847\n",
      "Accuracy for this batch: 77.999997139\n",
      "Accuracy for this batch: 86.0000014305\n",
      "Accuracy for this batch: 88.9999985695\n",
      "Accuracy for this batch: 80.0000011921\n",
      "Accuracy for this batch: 87.9999995232\n",
      "Accuracy for this batch: 88.9999985695\n",
      "Accuracy for this batch: 88.9999985695\n",
      "Accuracy for this batch: 87.0000004768\n",
      "Accuracy for this batch: 81.0000002384\n",
      "Accuracy for this batch: 80.0000011921\n",
      "Accuracy for this batch: 81.0000002384\n",
      "Accuracy for this batch: 87.9999995232\n",
      "Accuracy for this batch: 80.0000011921\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (0, 250) for Tensor 'Placeholder_1:0', which has shape '(100, 250)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-604d1a44cbf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnextBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextBatchLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTestBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy for this batch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnextBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnextBatchLabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/pratik/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pratik/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (0, 250) for Tensor 'Placeholder_1:0', which has shape '(100, 250)'"
     ]
    }
   ],
   "source": [
    "test_batches = 100\n",
    "for j in range(test_batches):\n",
    "    nextBatch, nextBatchLabels = getTestBatch(j);\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
